{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First going to work out some ideas in a jupyter notebook - Later I will clean this\n",
    "# up and and create some proper code.\n",
    "\n",
    "from typing import Iterator, NamedTuple\n",
    "\n",
    "# Getting some tensorflow warnings, but don't care about those right now\n",
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import optax\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import pathlib\n",
    "import string\n",
    "import glob2\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import keras\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow_probability.substrates import jax as tfp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import dataclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The IAM On-Line Handwriting Database (IAM-OnDB) is required for this project, so you will need to ask for\n",
    "# permission for that and download. https://fki.tic.heia-fr.ch/databases/iam-on-line-handwriting-database \n",
    "# Here we will create a wrapper class to give us some tensorflow dataset summaries of just the writing portion.\n",
    "\n",
    "class WritingGenerator():\n",
    "    def __init__(self, f_name, batch_size=32):   \n",
    "        self.all_x = []\n",
    "        self.all_y = []\n",
    "\n",
    "        # How we might pad each stroke to a consistent length and batch it for fitting - With the amount \n",
    "        # of data in the database and the complexity of a Transformer, this should probably be kept to\n",
    "        # under 400 strokes and 20 characters. There is an issue here though that different people use \n",
    "        # different amounts of strokes/char and this can confuse the network. I am not sure there is an\n",
    "        # elegant way to handle that problem with a Transformer network, as we would need about 1500\n",
    "        # tokens to read in every writing sample fully with padding and this is beyond a standard \n",
    "        # Transformer. Perhaps a PerceiverAR is next?\n",
    "        self.MAX_STROKE_LEN = 100\n",
    "        self.MAX_CHAR_SEQ_LEN = 5         \n",
    "        \n",
    "        self.f_name = f_name\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.padding_value = -1.\n",
    "        self.char_padding_value = 0.\n",
    "\n",
    "        # You will need to change this and point to your own database where you unzipped all of the \n",
    "        # IAM-OnDB strokes and corresponding ascii\n",
    "        base_dir_strokes='../IamONDB/lineStrokes'\n",
    "        base_dir_ascii='../IamONDB/ascii'\n",
    "        \n",
    "        try:\n",
    "            f = open(f_name, 'r')\n",
    "        except IOError:\n",
    "            print(\"Error opening file\")\n",
    "            return 0\n",
    "      \n",
    "        f_train = list(f)\n",
    "        f.close()\n",
    "        \n",
    "        self.n_samp = len(f_train)\n",
    "\n",
    "        print('Reading ' + str(self.n_samp) + ' files')\n",
    "\n",
    "        # This will contain a list of all stroke files\n",
    "        self.f_sub_list_strokes = []\n",
    "        # This will contain a list of corresponding ascii line files\n",
    "        self.f_sub_list_ascii = []\n",
    "\n",
    "        # First create a list of all subfiles in the .txt list - we are going to treat each line as a separate sample here\n",
    "        for i, fname in enumerate(f_train):\n",
    "            path_stroke = glob2.glob(base_dir_strokes + '/' + fname.strip()[0:3] + '/' + fname.strip()[0:7] + '/' + fname.strip() + '-*.xml')    \n",
    "              \n",
    "            self.f_sub_list_strokes += path_stroke\n",
    "\n",
    "            path_line = glob2.glob(base_dir_ascii + '/' + fname.strip()[0:3] + '/' + fname.strip()[0:7] + '/' + fname.strip() + '.txt')   \n",
    "            # We want a 1 to 1 matching of strokes to ascii.  We will pull out the appropriate line when we create the dataset\n",
    "            self.f_sub_list_ascii += path_line * len(path_stroke)\n",
    "                        \n",
    "        # list datasets\n",
    "        self.list_ds_strokes = tf.data.Dataset.from_tensor_slices(self.f_sub_list_strokes)\n",
    "        self.list_ds_ascii = tf.data.Dataset.from_tensor_slices(self.f_sub_list_ascii)\n",
    "\n",
    "        # Text helper functions and variables.  All lines of text need to be one-hot-encoded for proper integration into the attention\n",
    "        # mechanism of the model\n",
    "        self.vocab = string.printable\n",
    "\n",
    "        # I am adding 1 to all character enumerations so that 0 is reserved for padding only and can be ignored in the model\n",
    "        self.char2idx = {u: i+1 for i, u in enumerate(self.vocab)}\n",
    "        self.idx2char = {i+1: u for i, u in enumerate(self.vocab)}\n",
    "\n",
    "        self.invert_one_hot = lambda x: tf.argmax(x, -1).numpy()\n",
    "\n",
    "        self.text_to_int = lambda x: np.array([self.char2idx[c] for c in x])\n",
    "        self.int_to_text = lambda x: ''.join(np.array([self.idx2char[i] for i in x]))\n",
    "\n",
    "        # Combine\n",
    "        self.list_ds = tf.data.Dataset.zip((self.list_ds_strokes, self.list_ds_ascii))\n",
    "        \n",
    "        # Create a datbase of tuples (strokes, matching ascii)\n",
    "        self.labeled_ds = self.list_ds.map(lambda x, y: tf.py_function(self.process_stroke, (x, y), (tf.float32, tf.float32)))\n",
    "        \n",
    "        self.cached_example_dataset = self.labeled_ds.shuffle(buffer_size=1024).cache().take(1024)\n",
    "        \n",
    "    # Create a dataset of strokes and matching lines - As mentioned before, each line is a training sample in this version\n",
    "    def process_stroke(self, file_path_stroke, file_path_lines):\n",
    "        line_num = int(file_path_stroke.numpy()[-6:-4])\n",
    "        strokes = self.get_strokes(file_path_stroke.numpy())\n",
    "        # Not sure the best way to combine two files\n",
    "        lines = self.get_ascii(file_path_lines)\n",
    "\n",
    "        U = lines[line_num-1]\n",
    "        U = U[:self.MAX_CHAR_SEQ_LEN]\n",
    "        U_conv = tf.keras.backend.one_hot(self.text_to_int(U), len(self.vocab)+1)\n",
    "\n",
    "        return strokes, U_conv\n",
    "\n",
    "    # Returns only the strokes of the dataset as a tuple with a label of the same data 1 timestamp ahead\n",
    "    @property\n",
    "    def batched_set(self):\n",
    "        # We don't care about the line data for this version, so remove that first\n",
    "\n",
    "        stroke_only_ds=self.labeled_ds.map(lambda x, y: x)\n",
    "        \n",
    "        # All sequences will be strictly right padded so that tensorflow will run them on a GPU\n",
    "        batched_dataset = stroke_only_ds.padded_batch(self.batch_size, padded_shapes=([self.MAX_STROKE_LEN, 3]), \n",
    "                                                      drop_remainder=True, padding_values=self.padding_value)\n",
    "\n",
    "        return batched_dataset.map(self.dense_1_step).cache()\n",
    "        return batched_dataset.cache()\n",
    "\n",
    "    # Returns only the strokes of the dataset as a tuple with a label of the same data 1 timestamp ahead\n",
    "    # This one also returns the character sequence U being written as a one-hot-encoded tensor\n",
    "    @property\n",
    "    def batched_onehot_set(self):\n",
    "        batched_dataset_one_hot = self.labeled_ds.padded_batch(\n",
    "            self.batch_size, padded_shapes=([self.MAX_STROKE_LEN, 3], \n",
    "                                            [self.MAX_CHAR_SEQ_LEN, len(self.vocab)+1]), \n",
    "                                            drop_remainder=False, padding_values=(self.padding_value, self.char_padding_value))        \n",
    "\n",
    "        return batched_dataset_one_hot.map(self.dense_1_step)\n",
    "\n",
    "    # We will make our prediction 1 step ahead\n",
    "    def dense_1_step(self, batch_stroke, batch_char_seq):\n",
    "        # Shift features and labels one step relative to each other.\n",
    "        return (batch_stroke[:, :, :], batch_char_seq ), batch_stroke[:, :, :]\n",
    "    \n",
    "    def get_examples(self, num_examples):\n",
    "        example_dataset = self.labeled_ds.shuffle(100).take(num_examples)\n",
    "        \n",
    "        #example_dataset = self.labeled_ds.batch(1).shuffle(100).take(num_examples)\n",
    "        \n",
    "        return example_dataset\n",
    "        \n",
    "    def get_strokes(self, fname):\n",
    "        root = ET.parse(fname).getroot()\n",
    "\n",
    "        # Parse one xml file\n",
    "        strokeset = root.find('StrokeSet')\n",
    "\n",
    "        x_samp = []\n",
    "\n",
    "        for stroke in strokeset.iter('Stroke'):\n",
    "            for child in stroke:\n",
    "                x_samp.append([float(child.attrib.get('x')), -1*float(child.attrib.get('y')), 0.])\n",
    "\n",
    "            # As in Graves, 2013, we add a binary vector indicating the end of a stroke\n",
    "            x_samp[-1][-1]=1.0\n",
    "\n",
    "        x_samp = np.asarray(x_samp)\n",
    "        x_samp = x_samp[:self.MAX_STROKE_LEN, :]\n",
    "\n",
    "        # We want the data as offsets though, not raw strokes - easier to train a network to predict small changes in the next timestamp\n",
    "        x_off = np.hstack(([x_samp[1:, :2]-x_samp[:-1, :2], x_samp[1:, 2:3]]))\n",
    "        x_off = np.vstack(([0, 0, 0], x_off))\n",
    "\n",
    "        x_off[:, 0] /= np.std(x_off[:, 0])\n",
    "        x_off[:, 1] /= np.std(x_off[:, 1])\n",
    "\n",
    "        return x_off\n",
    " \n",
    "    # Read an ascii file form the iamONDB and return all of the lines as strings\n",
    "    def get_ascii(self, fname):\n",
    "        text_file = open(fname.numpy(), \"r\")\n",
    "        lines = text_file.read()\n",
    "        lines = lines.split('CSR:')\n",
    "\n",
    "        return lines[1].strip().split('\\n')       \n",
    "    \n",
    "    def __repr__(self):\n",
    "        return '\\n'.join([\n",
    "            f'Writing Dataset for: {self.f_name}'\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawing function for strokes\n",
    "# TODO: This should be in the writing class\n",
    "\n",
    "def plot_stroke(offsets, lines):\n",
    "    plt.figure(num=None, figsize=(15, 4))\n",
    "    strokes=np.array([np.cumsum(offsets[:,0]), np.cumsum(offsets[:,1]), offsets[:,2]]);    \n",
    "    stroke=[]\n",
    "\n",
    "    strokes[-1, -1] = 1\n",
    "\n",
    "    for x, y, eos in strokes.T:\n",
    "        stroke.append([x, y])\n",
    "        if eos > 0.1:\n",
    "            stroke=np.asarray(stroke);\n",
    "            #print(stroke.shape)\n",
    "            plt.plot(stroke[:,0], stroke[:,1], 'k')\n",
    "            stroke = []\n",
    "\n",
    "    clean_txt = lines\n",
    "\n",
    "    clean_txt = np.delete(clean_txt, np.argmax(clean_txt, -1) == 0.0, axis=0)\n",
    "\n",
    "    # TODO: This should be passed in\n",
    "    plt.title(train.int_to_text(train.invert_one_hot(clean_txt)))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 1726 files\n"
     ]
    }
   ],
   "source": [
    "# I concatenated all data into one set as we just want the maximum amount of data to train the \n",
    "# network to write and don't really care about evaluation or test sets for this project\n",
    "train = WritingGenerator('../IamONDB/trainset_d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inspect our dataset.  It returns a tuple of stroke offsets and matching ascii strings\n",
    "# You can see that there isn't an exact match for every subject for strokes to ascii \n",
    "# because of the token limit in Transformers\n",
    "SUB = 3\n",
    "\n",
    "for s, l in train.batched_onehot_set.take(2).cache():\n",
    "    plot_stroke(s[0][SUB, :, :], s[1][SUB, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Much of the following code is from the excellent Tensorflow tutorial on Transformers: https://www.tensorflow.org/text/tutorials/transformer\n",
    "\n",
    "# STEP 1 - Positional Embeddings from the original paper. Although, you can also just add a randomized vector and I may try that next\n",
    "# TODO: Switch to a random vector and see if performance suffers vs this complex embedding.\n",
    "\n",
    "def get_angles(pos, i, d_model):\n",
    "  angle_rates = 1 / jnp.power(10000, (2 * (i//2)) / jnp.float32(d_model))\n",
    "  return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "  angle_rads = get_angles(jnp.arange(position)[:, jnp.newaxis],\n",
    "                          jnp.arange(d_model)[jnp.newaxis, :],\n",
    "                          d_model)\n",
    "\n",
    "  # apply sin to even indices in the array; 2i\n",
    "  angle_rads = angle_rads.at[:, 0::2].set(jnp.sin(angle_rads[:, 0::2]))\n",
    "\n",
    "  # apply cos to odd indices in the array; 2i+1\n",
    "  angle_rads = angle_rads.at[:, 1::2].set(jnp.cos(angle_rads[:, 1::2]))\n",
    "\n",
    "  pos_encoding = angle_rads[jnp.newaxis, ...]\n",
    "\n",
    "  return pos_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build up some pieces in haiku. See: https://github.com/deepmind/dm-haiku/tree/main/examples/transformer\n",
    "\n",
    "def layer_norm(x: jnp.ndarray) -> jnp.ndarray:\n",
    "  \"\"\"Applies a unique LayerNorm to x with default settings.\"\"\"\n",
    "  ln = hk.LayerNorm(axis=-1, create_scale=True, create_offset=True)\n",
    "  return ln(x)\n",
    "\n",
    "def point_wise_feed_forward(x: jnp.ndarray, d_model: int, dff: int) -> jnp.ndarray:\n",
    "  mlp = hk.Sequential([\n",
    "      hk.Linear(dff, name='Lin1'), jax.nn.relu, # (batch_size, seq_len, dff)\n",
    "      hk.Linear(d_model, name='Lin2'),          # (batch_size, seq_len, d_model)\n",
    "  ])\n",
    "  return mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test out the point_wise_feed_forward network\n",
    "network = hk.transform(point_wise_feed_forward)\n",
    "params = network.init(rng=jax.random.PRNGKey(42), x=jnp.zeros((32, 100)), d_model=128, dff=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Encoder - Self attention over the input characters - The only mask needed is padded characters\n",
    "class Encoder_Layer(hk.Module):\n",
    "    # The Encoder Layer is one stack of the Encoder, putting the multihead together \n",
    "    # with the point wise network and some normalization layers\n",
    "    def __init__(self, key_size, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "        super().__init__(name='EncoderLayer')\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.dff = dff\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        # In haiku the key_size is specified manually instead of d_model/num_heads. Internally, it \n",
    "        # will project Q, K, and V to dimensions (*leading_dims, num_heads, head_size) before \n",
    "        # computing attention logits. After that you can futher modify it to project to d_model.\n",
    "        # TODO: Define an initializer here?\n",
    "        self.mha = hk.MultiHeadAttention(num_heads=num_heads, key_size=key_size, model_size=d_model, w_init_scale=1)\n",
    "\n",
    "    # I don't think haiku has any method for dealing with removing dropout automatically, so we will need\n",
    "    # to always pass in a training flag to remove it if necessary during inference\n",
    "    def __call__(\n",
    "        self,\n",
    "        x: jnp.ndarray,\n",
    "        mask,\n",
    "        training=True\n",
    "    ) -> jnp.ndarray:\n",
    "        # Need to format the mask properly across q_vals * k_vals\n",
    "        mask1 = mask[:, None, :, None] \n",
    "        mask2 = mask[:, None, None, :] \n",
    "        mask = mask1 & mask2  # [B, H=1, T, T]\n",
    "\n",
    "        attn_out = self.mha(x, x, x, mask)\n",
    "        if training:\n",
    "            attn_out = hk.dropout(hk.next_rng_key(), self.dropout_rate, attn_out)\n",
    "\n",
    "        # residual 1\n",
    "        attn_out = x + attn_out\n",
    "        attn_out = layer_norm(attn_out)\n",
    "\n",
    "        attn_out = point_wise_feed_forward(attn_out, self.d_model, self.dff)\n",
    "        if training:\n",
    "            attn_out = hk.dropout(hk.next_rng_key(), self.dropout_rate, attn_out)\n",
    "        \n",
    "        # residual 2\n",
    "        attn_out = x + attn_out\n",
    "        attn_out = layer_norm(attn_out)\n",
    "\n",
    "        return attn_out\n",
    "\n",
    "# The Encoder module handles the pre-processing of the character data - embedding + positional encoding\n",
    "# and looping over the requested number of encoder attention layers\n",
    "class Encoder(hk.Module):\n",
    "    def __init__(self, num_layers, key_size, d_model, num_heads, dff, maximum_positional_encoding, \n",
    "        dropout_rate=0.1):\n",
    "        super().__init__(name='Encoder')\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.d_model = d_model\n",
    "        self.dff = dff\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.enc_layers = [Encoder_Layer(key_size, d_model, num_heads, dff, dropout_rate) \n",
    "                       for _ in range(num_layers)]\n",
    "\n",
    "        # Postional encodings - enocodings are static in this case and not learned parameters\n",
    "        # TODO: Compare this to random\n",
    "        self.positional_embeddings = positional_encoding(maximum_positional_encoding, d_model)\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        x: jnp.ndarray,\n",
    "        mask,\n",
    "        training=True\n",
    "    ) -> jnp.ndarray:\n",
    "        # The mask for the encoder needs to be broadcastable to the last 2 dimensions (1, 1, T, T)\n",
    "        # because the multihead attention is parallel - See https://www.tensorflow.org/text/tutorials/transformer\n",
    "        \n",
    "        seq_len = jnp.shape(x)[1]\n",
    "        \n",
    "        # We are using one-hot encoded characters and not embedded words, so we will just use a\n",
    "        # prenet to connect that to our model of depth d_model instead\n",
    "        x = hk.Linear(self.d_model, name='prenet')(x)\n",
    "\n",
    "        x = x + self.positional_embeddings[:, :seq_len, :]\n",
    "\n",
    "        if training:\n",
    "            x = hk.dropout(hk.next_rng_key(), self.dropout_rate, x)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, mask, training)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Encoder - x input will be [B, T, d_model] embedded characters with positional encoding added\n",
    "x=s[1].numpy()\n",
    "\n",
    "mask = jnp.equal(jnp.sum(x, -1), 0)\n",
    "\n",
    "def encoder(x: jnp.ndarray, mask: jnp.ndarray) -> jnp.ndarray:\n",
    "    enc = Encoder(4, 32, 128, 4, 128, 200)\n",
    "\n",
    "    return enc(x, mask)\n",
    "\n",
    "network = hk.transform(encoder)\n",
    "key = jax.random.PRNGKey(42) \n",
    "params = network.init(rng=key, x=jnp.ones((32, 7, 101)), mask=mask)\n",
    "\n",
    "out = network.apply(params, key, x=x, mask=mask)\n",
    "\n",
    "#params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Decoder - Very similar to the Encoder with a self-attention mechanism, but there is a second cross-attention mechanism with\n",
    "# the output of the Encoder as K, V and the outputs of the self-attention mechanism as Q. That is, as the Decoder attemps to draw\n",
    "# hand written text based on the Encoder characters, it asks what parts of the encoding are important. Hopefully it learns this \n",
    "# relationship and we should see that reflected in the attention weights. It uses additional causal-masking to prevent future tokens\n",
    "# from being attended to as it attempts to predict the next token.\n",
    "\n",
    "class Decoder_Layer(hk.Module):\n",
    "    # The Decoder Layer is one stack of the Decoder, putting the 2 multihead attention blocks together \n",
    "    # with the point wise network and some normalization layers\n",
    "    def __init__(self, key_size, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "        super().__init__(name='DecoderLayer')\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.dff = dff\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.mha_self = hk.MultiHeadAttention(num_heads=num_heads, key_size=key_size, model_size=d_model, w_init_scale=1)\n",
    "        self.mha_cross = hk.MultiHeadAttention(num_heads=num_heads, key_size=key_size, model_size=d_model, w_init_scale=1)\n",
    "\n",
    "    # Mask here will only deal with the padding mask. We will compute the causal mask as needed in the calling function\n",
    "    def __call__(\n",
    "        self,\n",
    "        x: jnp.ndarray,\n",
    "        enc_output: jnp.ndarray,\n",
    "        mask,       # Mask of stroke padding\n",
    "        enc_mask,   # Mask of character padding\n",
    "        training=True\n",
    "    ) -> jnp.ndarray:\n",
    "        seq_len = jnp.shape(x)[1]\n",
    "\n",
    "        # Need to format the mask properly across q_vals * k_vals\n",
    "        mask1 = mask[:, None, :, None] \n",
    "        mask2 = mask[:, None, None, :] \n",
    "        mask2 = mask1 & mask2  # [B, H=1, T, T]\n",
    "\n",
    "        # Compute the causal mask and combine with the padding mask for the strokes\n",
    "        causal_mask = np.tril(np.ones((1, 1, seq_len, seq_len)))  # [B=1, H=1, T, T]\n",
    "        self_mask = mask2 * causal_mask  # [B, H=1, T, T]\n",
    "\n",
    "        # Self-attention\n",
    "        attn_out = self.mha_self(x, x, x, self_mask)\n",
    "        if training:\n",
    "            attn_out = hk.dropout(hk.next_rng_key(), self.dropout_rate, attn_out)\n",
    "\n",
    "        # residual 1\n",
    "        attn_out = x + attn_out\n",
    "        attn_out = layer_norm(attn_out)\n",
    "\n",
    "        # Cross-attention\n",
    "        # Combine the 2 padding masks. We don't need to attend to encodings that are padded or \n",
    "        # query decodings that are padded\n",
    "\n",
    "        # Need to format the mask properly across q_vals * k_vals\n",
    "        # TODO: This code is repeated a lot. This needs to be refactored.\n",
    "        mask1 = mask[:, None, :, None] \n",
    "        mask2 = enc_mask[:, None, None, :] \n",
    "        cross_mask = mask1 & mask2  # [B, H=1, T, T]\n",
    "        attn_out = self.mha_cross(attn_out, enc_output, enc_output, cross_mask)\n",
    "        if training:\n",
    "            attn_out = hk.dropout(hk.next_rng_key(), self.dropout_rate, attn_out)\n",
    "\n",
    "        # residual 2\n",
    "        attn_out = x + attn_out\n",
    "        attn_out = layer_norm(attn_out)\n",
    "\n",
    "        attn_out = point_wise_feed_forward(attn_out, self.d_model, self.dff)\n",
    "        if training:\n",
    "            attn_out = hk.dropout(hk.next_rng_key(), self.dropout_rate, attn_out)\n",
    "        \n",
    "        # residual 3\n",
    "        attn_out = x + attn_out\n",
    "        attn_out = layer_norm(attn_out)\n",
    "\n",
    "        # TODO: It looks like the haiku transformer does not allow the return of the attent weights,\n",
    "        # only the final projection. I am going to fork my own repo and add that (maybe pull request as well)\n",
    "        return attn_out\n",
    "\n",
    "def decoder_prenet(x: jnp.ndarray, d_model: int) -> jnp.ndarray:\n",
    "  mlp = hk.Sequential([\n",
    "      hk.Linear(d_model, name='D_Prenet1'), jax.nn.relu,    # (batch_size, seq_len, d_model)\n",
    "      hk.Linear(d_model, name='D_Prenet2'), jax.nn.relu,   # (batch_size, seq_len, d_model)\n",
    "      hk.Linear(d_model, name='D_Prenet3')                 # (batch_size, seq_len, d_model)\n",
    "  ])\n",
    "  return mlp(x)\n",
    "\n",
    "# The Decoder module handles the pre-processing of the stroke data - embedding + positional encoding\n",
    "# and looping over the requested number of decoder attention layers\n",
    "class Decoder(hk.Module):\n",
    "    def __init__(self, num_layers, key_size, d_model, num_heads, dff, maximum_positional_encoding, \n",
    "        dropout_rate=0.1):\n",
    "        super().__init__(name='Decoder')\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.d_model = d_model\n",
    "        self.dff = dff\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.dec_layers = [Decoder_Layer(key_size, d_model, num_heads, dff, dropout_rate) \n",
    "                       for _ in range(num_layers)]\n",
    "\n",
    "        # Postional encodings - enocodings are static in this case and not learned parameters\n",
    "        # TODO: Compare this to random\n",
    "        self.positional_embeddings = positional_encoding(maximum_positional_encoding, d_model)\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        x: jnp.ndarray,\n",
    "        enc_output: jnp.ndarray,\n",
    "        enc_mask,\n",
    "        training=True\n",
    "    ) -> jnp.ndarray:\n",
    "        # The mask for the encoder needs to be broadcastable to the last 2 dimensions (1, 1, T, T)\n",
    "        # because the multihead attention is parallel - See https://www.tensorflow.org/text/tutorials/transformer\n",
    "        # TODO: padding_value should be passed in or made global\n",
    "        mask = jnp.equal(jnp.sum(x, -1), train.padding_value*3)\n",
    "\n",
    "        seq_len = jnp.shape(x)[1]\n",
    "        \n",
    "        # Adding a small MLP here to give the network an opportunity to construct filters and non-linear relationships\n",
    "        # among the raw stroke data\n",
    "        x = decoder_prenet(x, self.d_model)\n",
    "\n",
    "        x = x + self.positional_embeddings[:, :seq_len, :]\n",
    "\n",
    "        if training:\n",
    "            x = hk.dropout(hk.next_rng_key(), self.dropout_rate, x)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.dec_layers[i](x, enc_output, mask, enc_mask, training)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 100, 128)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Decoder - x input will be [B, T, d_model] embedded characters with positional encoding added\n",
    "x=s[1].numpy()\n",
    "\n",
    "mask = jnp.equal(jnp.sum(x, -1), 0)\n",
    "\n",
    "x=s[0].numpy()\n",
    "\n",
    "def decoder(x: jnp.ndarray, enc_output: jnp.ndarray, enc_mask: jnp.ndarray) -> jnp.ndarray:\n",
    "    dec = Decoder(4, 32, 128, 4, 128, 200)\n",
    "\n",
    "    return dec(x, enc_output, mask)\n",
    "\n",
    "network = hk.transform(decoder)\n",
    "key = jax.random.PRNGKey(42) \n",
    "params = network.init(rng=key, x=jnp.ones((32, 100, 3)), enc_output=out, enc_mask=mask)\n",
    "\n",
    "out2 = network.apply(params, key, x=x, enc_output=out, enc_mask=mask)\n",
    "\n",
    "out2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Writing Transformer\n",
    "\n",
    "# Output space - number of parameters in the mixture model\n",
    "NUM_MIX_COM = 20\n",
    "# weights + means (x + y) + std. devs. (x + y) + correlations + end_of_stroke\n",
    "# Unlike the Mixture Density Network notebook we are going to add cross correlation\n",
    "# terms to our loss and sampling functions for added complexity of the density \n",
    "# estimations\n",
    "NUM_PARAMS = NUM_MIX_COM + NUM_MIX_COM*2 + NUM_MIX_COM*2 + NUM_MIX_COM + 1\n",
    "\n",
    "class Writing_Transformer(hk.Module):\n",
    "    def __init__(self, num_layers, key_size, d_model, num_heads, dff, pe_encoding, pe_target, \n",
    "        dropout_rate=0.1):\n",
    "        super().__init__(name='Writing_Transformer')\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.d_model = d_model\n",
    "        self.dff = dff\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.enc = Encoder(num_layers, key_size, d_model, num_heads, dff, pe_encoding, dropout_rate)\n",
    "        self.dec = Decoder(num_layers, key_size, d_model, num_heads, dff, pe_target, dropout_rate)\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        inp: jnp.ndarray,\n",
    "        tar: jnp.ndarray,\n",
    "        training=True\n",
    "    ) -> jnp.ndarray:\n",
    "        enc_mask = jnp.equal(jnp.sum(inp, -1), 0)\n",
    "\n",
    "        # The Encoder\n",
    "        enc_output = self.enc(inp, enc_mask, training)\n",
    "\n",
    "        # The Decoder\n",
    "        dec_output = self.dec(tar, enc_output, enc_mask, training)\n",
    "\n",
    "        # The final layer to give us our logits\n",
    "        x = hk.Linear(NUM_PARAMS, name='final_layer')(dec_output)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 100, 121)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test The full network\n",
    "inp=s[1].numpy()\n",
    "tar=s[0].numpy()\n",
    "\n",
    "def writing_transformer(inp: jnp.ndarray, tar: jnp.ndarray) -> jnp.ndarray:\n",
    "    tra = Writing_Transformer(4, 32, 128, 4, 128, 200, 1000, 0.2)\n",
    "\n",
    "    return tra(inp, tar)\n",
    "\n",
    "network = hk.transform(writing_transformer)\n",
    "key = jax.random.PRNGKey(42) \n",
    "params = network.init(rng=key, inp=inp, tar=tar)\n",
    "\n",
    "out3 = network.apply(params, key, inp=inp, tar=tar)\n",
    "\n",
    "out3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now for the loss function\n",
    "# TODO: I think there are a lot of edge cases here that will result in NaNs when training.\n",
    "\n",
    "EPS = 0.000001\n",
    "\n",
    "@jax.jit\n",
    "def my_loss_fun_MDN(params: hk.Params, batch: tuple) -> jnp.ndarray:\n",
    "    # Predict the next strokes\n",
    "    key = jax.random.PRNGKey(42) \n",
    "\n",
    "    # We split the input and then use 1 sample ahead as the target (y_true)\n",
    "    inp = batch[0][:, :-1]\n",
    "    y_true = batch[0][:, 1:]\n",
    "\n",
    "    logits = network.apply(params, key, batch[1], inp)\n",
    "\n",
    "    pis, mu, sig, rho, eos = jnp.array_split(logits, [NUM_MIX_COM, NUM_MIX_COM*3, NUM_MIX_COM*5, NUM_MIX_COM*6], axis=-1)\n",
    "    \n",
    "    #print(eos.shape)\n",
    "\n",
    "    # weights - must be a probability distribution so softmax over all components\n",
    "    pis = jax.nn.softmax(pis)\n",
    "    \n",
    "    # means - no transformation needed\n",
    "    mu_x1, mu_x2 = jnp.array_split(mu, 2, axis=-1)\n",
    "    \n",
    "    # standard deviations - must be strictly positive so exponent\n",
    "    sig = jnp.exp(sig)\n",
    "    \n",
    "    sig = jnp.clip(sig, EPS, np.inf)\n",
    "    \n",
    "    sig_x1, sig_x2 = jnp.array_split(sig, 2, axis=-1)\n",
    "    \n",
    "    x1, x2, eos_true = jnp.array_split(y_true, 3, axis=-1)\n",
    "    \n",
    "    eos_true = jnp.squeeze(eos_true)\n",
    "\n",
    "    #print(eos_true.shape)\n",
    "        \n",
    "    # correlations - squish to -1 to 1 with tanh activation\n",
    "    rho = jnp.tanh(rho)\n",
    "    \n",
    "    rho = jnp.clip(rho, -1.+EPS, 1.-EPS)\n",
    "    \n",
    "    # Define Z as in Graves, 2013\n",
    "    Z = jnp.square( ( x1-mu_x1 ) / sig_x1 ) + jnp.square( ( x2-mu_x2 ) / sig_x2 ) - ( 2 * rho * (x1-mu_x1) * (x2-mu_x2) ) / ( sig_x1*sig_x2 )\n",
    "    \n",
    "    one_minus_rho_square = 1. - jnp.square(rho)\n",
    "    \n",
    "    # Now form Gaussian mixtures\n",
    "    term1 = jnp.divide(1., ( 2. * np.pi * sig_x1 * sig_x2 * jnp.sqrt( one_minus_rho_square ) ))\n",
    "    term2 = jnp.exp( jnp.divide ( (-1. * Z) , (2.*( one_minus_rho_square )) ))\n",
    "    \n",
    "    mix_loss = jnp.sum(pis * term1 * term2, axis=-1)       \n",
    "    \n",
    "    mix_loss = jnp.clip(mix_loss, EPS, np.inf)\n",
    "\n",
    "    # end of stroke loss\n",
    "    eos = jnp.squeeze(jax.nn.sigmoid(eos))\n",
    "    \n",
    "    eos = jnp.clip(eos, EPS, 1.-EPS)\n",
    "    \n",
    "    eos_loss = jnp.where(jnp.equal(eos_true, 1.), eos, 1.-eos)\n",
    "    \n",
    "    # Only the valid parts of the sequence should count towards the loss.  The invalid parts are tagged with -2200\n",
    "    val_seq = jnp.squeeze(jnp.not_equal(eos_true, train.padding_value))\n",
    "\n",
    "    # This is the total loss for each element (batch * num_timepoints)\n",
    "    tot_loss = -(jnp.log(mix_loss) + jnp.log(eos_loss))\n",
    "\n",
    "    # The sequence loss is the sum of only the valid timepoints\n",
    "    \n",
    "    tot_loss = jnp.where(val_seq, tot_loss, 0.)   \n",
    "    \n",
    "    seq_tot = jnp.sum(val_seq, axis=-1)\n",
    "\n",
    "    #seq_tot = tf.cast(seq_tot, tf.float32)\n",
    "\n",
    "    tot_loss = jnp.sum(tot_loss, axis=-1) / seq_tot   \n",
    "\n",
    "    return jnp.mean(tot_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 99)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray(0.3622175, dtype=float32)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test out the loss function\n",
    "data = train.batched_onehot_set.prefetch(tf.data.experimental.AUTOTUNE).as_numpy_iterator()\n",
    "\n",
    "out4 = my_loss_fun_MDN(params, data.next()[0])\n",
    "\n",
    "out4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "learning_rate = 0.0001\n",
    "\n",
    "num_layers = 2\n",
    "key_size = 32\n",
    "d_model = 128\n",
    "dff = 256\n",
    "num_heads = 4\n",
    "dropout_rate = 0.1\n",
    "\n",
    "def writing_transformer(inp: jnp.ndarray, tar: jnp.ndarray) -> jnp.ndarray:\n",
    "    tra = Writing_Transformer(num_layers, key_size, d_model, num_heads, dff, pe_encoding=250, pe_target=1000, dropout_rate=dropout_rate)\n",
    "\n",
    "    return tra(inp, tar)\n",
    "\n",
    "network = hk.transform(writing_transformer)\n",
    "\n",
    "@jax.jit\n",
    "def update(params: hk.Params, opt_state: optax.OptState, batch: tuple):\n",
    "  grad = jax.grad(my_loss_fun_MDN)(params, batch)\n",
    "  updates, opt_state = optimiser.update(grad, opt_state)\n",
    "  params = optax.apply_updates(params, updates)\n",
    "\n",
    "  return params, opt_state\n",
    "\n",
    "# TODO: make fetching the iterator more elegant and does the conversion from numpy to jax slow things down?\n",
    "#b = train.batched_onehot_set.prefetch(tf.data.experimental.AUTOTUNE).as_numpy_iterator()\n",
    "key = jax.random.PRNGKey(42) \n",
    "#s = next(b)[0]\n",
    "params = network.init(rng=key, inp=inp, tar=tar)\n",
    "\n",
    "\n",
    "\n",
    "  # Average loss?\n",
    "  #data_iter = train.batched_onehot_set.prefetch(tf.data.experimental.AUTOTUNE).as_numpy_iterator()\n",
    "  #total_loss = 0\n",
    "  #for b, _ in data_iter:\n",
    "  #  total_loss = total_loss + my_loss_fun_MDN(params, b)\n",
    "\n",
    "  #print(\"   loss {:0.4f}\".format(total_loss*BATCH/20000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': 0}\n",
      "Epoch 1 Batch 0 Loss 0.4014\n",
      "Epoch 1 Batch 50 Loss 0.2261\n",
      "Epoch 1 Batch 100 Loss 0.1929\n",
      "Epoch 1 Batch 150 Loss 0.1874\n",
      "Epoch 1 Batch 200 Loss 0.1529\n",
      "Epoch 1 Batch 250 Loss 0.1406\n",
      "Epoch 1 Batch 300 Loss 0.1330\n",
      "Epoch 1 Batch 350 Loss 0.1255\n",
      "Epoch 1 Loss 0.1220\n",
      "{'Epoch': 1}\n",
      "Epoch 2 Batch 0 Loss 0.4286\n",
      "Epoch 2 Batch 50 Loss 0.2247\n",
      "Epoch 2 Batch 100 Loss 0.1899\n",
      "Epoch 2 Batch 150 Loss 0.1841\n",
      "Epoch 2 Batch 200 Loss 0.1493\n",
      "Epoch 2 Batch 250 Loss 0.1368\n",
      "Epoch 2 Batch 300 Loss 0.1291\n",
      "Epoch 2 Batch 350 Loss 0.1215\n",
      "Epoch 2 Loss 0.1180\n",
      "{'Epoch': 2}\n",
      "Epoch 3 Batch 0 Loss 0.4283\n",
      "Epoch 3 Batch 50 Loss 0.2212\n",
      "Epoch 3 Batch 100 Loss 0.1865\n",
      "Epoch 3 Batch 150 Loss 0.1805\n",
      "Epoch 3 Batch 200 Loss 0.1456\n",
      "Epoch 3 Batch 250 Loss 0.1330\n",
      "Epoch 3 Batch 300 Loss 0.1254\n",
      "Epoch 3 Batch 350 Loss 0.1177\n",
      "Epoch 3 Loss 0.1142\n",
      "{'Epoch': 3}\n",
      "Epoch 4 Batch 0 Loss 0.4266\n",
      "Epoch 4 Batch 50 Loss 0.2176\n",
      "Epoch 4 Batch 100 Loss 0.1829\n",
      "Epoch 4 Batch 150 Loss 0.1769\n",
      "Epoch 4 Batch 200 Loss 0.1420\n",
      "Epoch 4 Batch 250 Loss 0.1294\n",
      "Epoch 4 Batch 300 Loss 0.1217\n",
      "Epoch 4 Batch 350 Loss 0.1140\n",
      "Epoch 4 Loss 0.1104\n",
      "{'Epoch': 4}\n",
      "Epoch 5 Batch 0 Loss 0.4242\n",
      "Epoch 5 Batch 50 Loss 0.2142\n",
      "Epoch 5 Batch 100 Loss 0.1795\n",
      "Epoch 5 Batch 150 Loss 0.1734\n",
      "Epoch 5 Batch 200 Loss 0.1385\n",
      "Epoch 5 Batch 250 Loss 0.1258\n",
      "Epoch 5 Batch 300 Loss 0.1181\n",
      "Epoch 5 Batch 350 Loss 0.1104\n",
      "Epoch 5 Loss 0.1068\n",
      "{'Epoch': 5}\n",
      "Epoch 6 Batch 0 Loss 0.4219\n",
      "Epoch 6 Batch 50 Loss 0.2109\n",
      "Epoch 6 Batch 100 Loss 0.1763\n",
      "Epoch 6 Batch 150 Loss 0.1701\n",
      "Epoch 6 Batch 200 Loss 0.1351\n",
      "Epoch 6 Batch 250 Loss 0.1224\n",
      "Epoch 6 Batch 300 Loss 0.1147\n",
      "Epoch 6 Batch 350 Loss 0.1069\n",
      "Epoch 6 Loss 0.1032\n",
      "{'Epoch': 6}\n",
      "Epoch 7 Batch 0 Loss 0.4196\n",
      "Epoch 7 Batch 50 Loss 0.2078\n",
      "Epoch 7 Batch 100 Loss 0.1731\n",
      "Epoch 7 Batch 150 Loss 0.1669\n",
      "Epoch 7 Batch 200 Loss 0.1318\n",
      "Epoch 7 Batch 250 Loss 0.1190\n",
      "Epoch 7 Batch 300 Loss 0.1113\n",
      "Epoch 7 Batch 350 Loss 0.1034\n",
      "Epoch 7 Loss 0.0997\n",
      "{'Epoch': 7}\n",
      "Epoch 8 Batch 0 Loss 0.4171\n",
      "Epoch 8 Batch 50 Loss 0.2047\n",
      "Epoch 8 Batch 100 Loss 0.1699\n",
      "Epoch 8 Batch 150 Loss 0.1637\n",
      "Epoch 8 Batch 200 Loss 0.1285\n",
      "Epoch 8 Batch 250 Loss 0.1156\n",
      "Epoch 8 Batch 300 Loss 0.1079\n",
      "Epoch 8 Batch 350 Loss 0.1000\n",
      "Epoch 8 Loss 0.0963\n",
      "{'Epoch': 8}\n",
      "Epoch 9 Batch 0 Loss 0.4151\n",
      "Epoch 9 Batch 50 Loss 0.2016\n",
      "Epoch 9 Batch 100 Loss 0.1668\n",
      "Epoch 9 Batch 150 Loss 0.1604\n",
      "Epoch 9 Batch 200 Loss 0.1252\n",
      "Epoch 9 Batch 250 Loss 0.1123\n",
      "Epoch 9 Batch 300 Loss 0.1046\n",
      "Epoch 9 Batch 350 Loss 0.0966\n",
      "Epoch 9 Loss 0.0928\n",
      "{'Epoch': 9}\n",
      "Epoch 10 Batch 0 Loss 0.4131\n",
      "Epoch 10 Batch 50 Loss 0.1985\n",
      "Epoch 10 Batch 100 Loss 0.1636\n",
      "Epoch 10 Batch 150 Loss 0.1572\n",
      "Epoch 10 Batch 200 Loss 0.1220\n",
      "Epoch 10 Batch 250 Loss 0.1090\n",
      "Epoch 10 Batch 300 Loss 0.1012\n",
      "Epoch 10 Batch 350 Loss 0.0933\n",
      "Epoch 10 Loss 0.0894\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "\n",
    "optimiser = optax.adam(learning_rate)\n",
    "opt_state = optimiser.init(params)\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "\n",
    "for step in range(EPOCHS):\n",
    "  data_iter = train.batched_onehot_set.prefetch(tf.data.experimental.AUTOTUNE).as_numpy_iterator()\n",
    "\n",
    "  train_loss.reset_states()\n",
    "\n",
    "  print({\"Epoch\": step})\n",
    "  for (batch, (b, _)) in enumerate(data_iter):\n",
    "    params, opt_state = update(params, opt_state, b)\n",
    "\n",
    "    loss = my_loss_fun_MDN(params, b)\n",
    "    train_loss(loss)\n",
    "\n",
    "    if batch % 50 == 0:\n",
    "      print(f'Epoch {step + 1} Batch {batch} Loss {train_loss.result():.4f}')\n",
    "\n",
    "  print(f'Epoch {step + 1} Loss {train_loss.result():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also need our own sampling function in this case\n",
    "from tensorflow_probability.substrates import jax as tfp\n",
    "\n",
    "def fill_diagonal(a, val):\n",
    "  assert a.ndim >= 2\n",
    "  i, j = jnp.diag_indices(min(a.shape[-2:]))\n",
    "  return a.at[..., i, j].set(val)\n",
    "\n",
    "# sample the mixture model\n",
    "# input: res (mixture_components)\n",
    "#        b (temperature)\n",
    "# output: sample, pis, mean, variance\n",
    "def sample_mix_model(res, b):\n",
    "      #print(res.shape)\n",
    "      pis, mu, sig, rho, eos = jnp.array_split(res, [NUM_MIX_COM, NUM_MIX_COM*3, NUM_MIX_COM*5, NUM_MIX_COM*6], axis=-1)\n",
    "\n",
    "      # weights - must be a probability distribution so softmax over all components\n",
    "      pis = jax.nn.softmax(pis * (1+b))\n",
    "\n",
    "      # means - no transformation needed\n",
    "      mu_x1, mu_x2 = jnp.array_split(mu, 2, axis=-1)\n",
    "      \n",
    "      # standard deviations - must be strictly positive so exponent\n",
    "      sig = jnp.exp(sig - b)\n",
    "\n",
    "      sig_x1, sig_x2 = jnp.array_split(sig, 2, axis=-1)\n",
    "            \n",
    "      # correlations - squish to -1 to 1 with tanh activation\n",
    "      rho = jnp.tanh(rho)\n",
    "\n",
    "      a = jnp.zeros((NUM_MIX_COM, 2, 2))\n",
    "\n",
    "      S = fill_diagonal(a, jnp.stack([sig_x1, sig_x2], axis=-1))\n",
    "\n",
    "      #print(S.shape)\n",
    "\n",
    "      #E = jnp.eye(2, batch_shape=[NUM_MIX_COM])\n",
    "      E = jnp.repeat(jnp.eye(2)[None, :], NUM_MIX_COM, axis=0)\n",
    "\n",
    "      rho_exp = jnp.reshape(jnp.repeat(rho, 4), [NUM_MIX_COM, 2, 2])\n",
    "    \n",
    "      corr_mat = jnp.where(jnp.equal(E, 1.), E, rho_exp)\n",
    "      \n",
    "      cov_mat = jnp.matmul(S, corr_mat)\n",
    "      cov_mat = jnp.matmul(cov_mat, S)\n",
    "\n",
    "      # The distribution is a mixture of gaussians\n",
    "      gm = tfp.distributions.MixtureSameFamily(mixture_distribution=tfp.distributions.Categorical(probs=pis),\n",
    "            components_distribution=tfp.distributions.MultivariateNormalTriL(loc=jnp.stack([mu_x1, mu_x2], axis=-1),\n",
    "                                                                    scale_tril=jax.lax.linalg.cholesky(cov_mat)))\n",
    "\n",
    "      # End of stroke\n",
    "      eos = jax.nn.sigmoid(eos)\n",
    "      \n",
    "      bd = tfp.distributions.Bernoulli(probs=eos)\n",
    "      \n",
    "      bd_samp = bd.sample(seed=jax.random.PRNGKey(seed=42))\n",
    "      \n",
    "      #print(tf.concat([gm.sample(), eos], axis=-1))\n",
    "      \n",
    "      gm_samp = gm.sample(seed=jax.random.PRNGKey(seed=42))\n",
    "\n",
    "      return np.hstack((gm_samp, bd_samp, gm.mean(), gm.covariance().ravel(), pis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[[ 0.        ,  0.        ,  0.        ],\n",
       "              [-0.0192782 ,  0.00616334,  0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the sample function\n",
    "dec_input = jnp.zeros((1, 1, 3))\n",
    "one_hot_sentence = convert_sentence(encoding_sent)\n",
    "\n",
    "key = jax.random.PRNGKey(42) \n",
    "predictions_all = network.apply(params, key, one_hot_sentence, dec_input)\n",
    "\n",
    "predictions = sample_mix_model(predictions_all[0, -1, :], 1)\n",
    "\n",
    "pred_strokes = predictions[:3]\n",
    "pred_strokes = pred_strokes[jnp.newaxis, jnp.newaxis, :]\n",
    "\n",
    "pred_strokes.shape\n",
    "\n",
    "dec_input = jax.lax.concatenate([dec_input, pred_strokes], 1)\n",
    "#dec_input = jnp.stack([dec_input, pred_strokes])\n",
    "\n",
    "dec_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "def fill_diagonal(a, val):\n",
    "  assert a.ndim >= 2\n",
    "  i, j = jnp.diag_indices(min(a.shape[-2:]))\n",
    "  return a.at[..., i, j].set(val)\n",
    "\n",
    "a = jnp.zeros((2, 3, 4, 4))\n",
    "\n",
    "# works for scalars\n",
    "a1 = fill_diagonal(a, 2)\n",
    "\n",
    "# or for batched vectors\n",
    "a2 = fill_diagonal(a, jnp.arange(24).reshape(2, 3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 4, 4)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need an evaluate function that will take in a character sequence and \n",
    "# generate some writing\n",
    "\n",
    "# Convert a sentence to a one-hot-encoded vector\n",
    "def convert_sentence(sentence):\n",
    "  # Convert it to a one-hot encoded vector for the encoder\n",
    "  U_conv = tf.keras.backend.one_hot(train.text_to_int(sentence), len(train.vocab)+1)\n",
    "  #U_conv = train.text_to_int(sentence)\n",
    "  # Pad it to match the original data that was input into the encoder\n",
    "  U_conv = tf.keras.preprocessing.sequence.pad_sequences([U_conv],\n",
    "                                                         maxlen=train.MAX_CHAR_SEQ_LEN,\n",
    "                                                         padding='post',\n",
    "                                                         value=train.char_padding_value);\n",
    "  #U_conv = tf.convert_to_tensor(U_conv, dtype='float32')\n",
    "\n",
    "  return jnp.asarray(U_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5, 101)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding_sent = 'Hello'\n",
    "\n",
    "one_hot_sentence = convert_sentence(encoding_sent)\n",
    "\n",
    "one_hot_sentence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "\n",
    "output_name = \"test_attention.mp4\"\n",
    "\n",
    "b = 10.0\n",
    "\n",
    "def evaluate(U_conv):\n",
    "  #gen_sequence = np.zeros((1, 3))\n",
    "\n",
    "  dec_input = jnp.zeros((1, 1, 3))\n",
    "\n",
    "  MAX_LEN = 100\n",
    "\n",
    " # transformer.reset_states()\n",
    "\n",
    "  #fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    " # ims = []\n",
    "\n",
    "#  for t in range(int(train.MAX_STROKE_LEN)):\n",
    "  for t in range(int(MAX_LEN)):\n",
    "    # Create masks.  Even in the inference stage we may create input that is \n",
    "    # padded, such as the one-hot_sentence, and we always need a look-ahead \n",
    "    # mask\n",
    "    #enc_padding_mask, combined_mask, dec_padding_mask = create_masks(U_conv, dec_input)\n",
    "\n",
    "    key = jax.random.PRNGKey(40) \n",
    "\n",
    "    predictions_all = network.apply(params, key, U_conv, dec_input)\n",
    "\n",
    "    #predictions_all = transformer(U_conv,\n",
    "    #                                                     dec_input,\n",
    "     #                                                    False,\n",
    "     #                                                    enc_padding_mask,\n",
    "     #                                                    combined_mask,\n",
    "     #                                                    dec_padding_mask)\n",
    "\n",
    "    #data = tf.squeeze(attention_weights['decoder_layer1_block2'], 0)[0]\n",
    "  \n",
    "    #data_all = np.zeros((MAX_LEN, 20))\n",
    "\n",
    "    #data_all[:data.shape[0], :] = data\n",
    "\n",
    "    #ax = fig.add_subplot(1, 1, 1)\n",
    "    #im = plt.imshow(data_all, cmap='viridis', interpolation='nearest', aspect='auto', animated=True)\n",
    "\n",
    "    #ax = plt.gca()\n",
    "\n",
    "    #labels = 'Eye tracking....'\n",
    "\n",
    "    #ax.set_xticks(range(0, train.MAX_CHAR_SEQ_LEN-1))\n",
    "    #ax.set_xticklabels(labels)\n",
    "\n",
    "    #ax.set_xlabel('Characters to be Written')\n",
    "    #ax.set_ylabel('Stroke Number')\n",
    "\n",
    "    #ims.append([im])\n",
    "\n",
    "    predictions = sample_mix_model(predictions_all[0, -1, :], b)\n",
    "\n",
    "    pred_strokes = predictions[:3]\n",
    "    pred_strokes = pred_strokes[jnp.newaxis, jnp.newaxis, :]\n",
    "\n",
    "    #pred_strokes.shape\n",
    "\n",
    "    dec_input = jax.lax.concatenate([dec_input, pred_strokes], 1)\n",
    "\n",
    "    #print(dec_input.shape)\n",
    "\n",
    "    #print(dec_input.shape)\n",
    "\n",
    "  #ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True,\n",
    "   #                             repeat_delay=1000)\n",
    "  \n",
    "  #ani.save(output_name)\n",
    "\n",
    "  #plt.show()\n",
    "\n",
    "  #return dec_input.numpy(), attention_weights\n",
    "  return dec_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate(one_hot_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_stroke(results[0, :100, :], one_hot_sentence[0, :])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('ML-tests': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b163f0480e5ecb2ed0d5f04556597a429b2f653f97b785151c27d861fe015d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
